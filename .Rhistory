new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE, repos = "https://cloud.r-project.org")
sapply(pkg, require, character.only = TRUE)
}
package = c("ropenaq", "knitr", "xts", "PerformanceAnalytics")
ipak(package)
countries_table <- aq_countries()
kable(countries_table)
cities_tableIndia <- aq_cities(country="NL", page = 1)
kable(cities_tableIndia)
locations_chennai <- aq_locations(country = "NL", city = "Utrecht", parameter = "no2")
kable(locations_chennai)
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2" , limit = 20, date_from="2020-07-20", page = 1)
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2"  , date_from="2020-05-01", page = 1)
?aq_measurements
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2"  ,   page = 1)
results_table <- aq_measurements(country = "NL", city = "utrecht", parameter = "no2"  , date_from="2020-05-01", page = 1)
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2"  , date_from="2020-05-01", page = 1)
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2"  , date_from="2020-05-01", page = 1)
output <- aq_measurements(country='IN', limit=9, city='Chennai',
page = 1)
version("ropenaq")
sessionInfo()
results_table <- aq_measurements(country = "NL", city = "Utrecht", parameter = "no2"  , date_from="2020-05-01", page = 1)
load("~/Downloads/global_annual.Rda")
library(devtools)
use_data(global_annual)
use_data(global_annual, overwrite = T)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path = 'Figs_geohub/',
echo=T, include = T, warning = FALSE, message = FALSE)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
#repos='http://cran.muenster.r-project.org'
stdata = c("sp", "sf", "raster")
Stat_methods = c("lme4", "glmnet", "ranger", "gbm", "xgboost", "party", "caret", "gstat")
visual = c("RColorBrewer", "ggplot2", "corrplot", "tmap" )
map = c("maptools")
tidy = c("devtools", "dplyr",  "tidyr",  "knitr")
other = c("countrycode", "data.table", "Matrix", "GGally", "pdp")
optional = c("leafem",   "vip", "DT", "sparkline","leaflet", "mapview", "htmlwidgets", "rasterVis", "tibble", "shiny") # for the chuncks to be run after work shop or other experienments (other scripts but in this workshop).
packages <- c(stdata, tidy, Stat_methods, visual, map, other)
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
ls("package:APMtools")
#gd = fread("~/Documents/GitHub/Global mapping/2020_06_world/stations_20200602.csv")
#avg = fread("~/Documents/GitHub/Global mapping/oaqEUAUCAUS.csv")
#gdata = merge(gd, avg, by.x = c("long", "lat"), by.y = c("LONGITUDE","LATITUDE" ))
#g1 = na_if(gdata, -9999.9)
#g2 = g1%>%dplyr::select(-id, -dir, -V1)%>%filter(value_mean >0)
data("global_annual")
global_annual %>% dplyr::select(value_mean ) %>% summary()
#datatable(g2, rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T))
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
summary(global_annual)
summary(global_annual$value_mean)
load("~/Downloads/global_annual.Rda")
summary(global_annual$value_mean)
use_data(global_annual, overwrite = T)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path = 'Figs_geohub/',
echo=T, include = T, warning = FALSE, message = FALSE)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
#repos='http://cran.muenster.r-project.org'
stdata = c("sp", "sf", "raster")
Stat_methods = c("lme4", "glmnet", "ranger", "gbm", "xgboost", "party", "caret", "gstat")
visual = c("RColorBrewer", "ggplot2", "corrplot", "tmap" )
map = c("maptools")
tidy = c("devtools", "dplyr",  "tidyr",  "knitr")
other = c("countrycode", "data.table", "Matrix", "GGally", "pdp")
optional = c("leafem",   "vip", "DT", "sparkline","leaflet", "mapview", "htmlwidgets", "rasterVis", "tibble", "shiny") # for the chuncks to be run after work shop or other experienments (other scripts but in this workshop).
packages <- c(stdata, tidy, Stat_methods, visual, map, other)
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
ls("package:APMtools")
#gd = fread("~/Documents/GitHub/Global mapping/2020_06_world/stations_20200602.csv")
#avg = fread("~/Documents/GitHub/Global mapping/oaqEUAUCAUS.csv")
#gdata = merge(gd, avg, by.x = c("long", "lat"), by.y = c("LONGITUDE","LATITUDE" ))
#g1 = na_if(gdata, -9999.9)
#g2 = g1%>%dplyr::select(-id, -dir, -V1)%>%filter(value_mean >0)
data("global_annual")
vastring = "road|nightlight|population|temp|wind|trop|indu|elev"
global_annual %>% dplyr::select(value_mean ) %>% summary()
#datatable(g2, rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T))
install_github("mengluchu/APMtools")
library(APMtools)
ls("package:APMtools")
install_github("mengluchu/APMtools", force = T)
library(APMtools)
ls("package:APMtools")
#gd = fread("~/Documents/GitHub/Global mapping/2020_06_world/stations_20200602.csv")
#avg = fread("~/Documents/GitHub/Global mapping/oaqEUAUCAUS.csv")
#gdata = merge(gd, avg, by.x = c("long", "lat"), by.y = c("LONGITUDE","LATITUDE" ))
#g1 = na_if(gdata, -9999.9)
#g2 = g1%>%dplyr::select(-id, -dir, -V1)%>%filter(value_mean >0)
data("global_annual")
global_annual %>% dplyr::select(value_mean ) %>% summary()
#datatable(g2, rownames = FALSE, filter = "top", options = list(pageLength = 5, scrollX = T))
load("~/Downloads/global_annual.rda")
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
summary(global_annual$value_mean)
load("~/Downloads/global_annual.rda")
summary(global_annual$value_mean)
use_data(global_annual, overwrite = T)
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
use_data(global_annual, overwrite = T)
load("~/Downloads/global_annual.rda")
use_data(global_annual, overwrite = T)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path = 'Figs_geohub/',
echo=T, include = T, warning = FALSE, message = FALSE)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
#repos='http://cran.muenster.r-project.org'
stdata = c("sp", "sf", "raster")
Stat_methods = c("lme4", "glmnet", "ranger", "gbm", "xgboost", "party", "caret", "gstat")
visual = c("RColorBrewer", "ggplot2", "corrplot", "tmap" )
map = c("maptools")
tidy = c("devtools", "dplyr",  "tidyr",  "knitr")
other = c("countrycode", "data.table", "Matrix", "GGally", "pdp")
optional = c("leafem",   "vip", "DT", "sparkline","leaflet", "mapview", "htmlwidgets", "rasterVis", "tibble", "shiny") # for the chuncks to be run after work shop or other experienments (other scripts but in this workshop).
packages <- c(stdata, tidy, Stat_methods, visual, map, other)
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
ls("package:APMtools")
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
summary(global_annual$value_mean)
library(devtools)
use_data(global_annual, overwrite = T)
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
summary(global_annual$value_mean)
library(devtools)
use_data(global_annual, overwrite = T)
load("~/Documents/GitHub/Global mapping/station_predictor/global_annual.rda")
summary(global_annual$value_mean)
library(devtools)
use_data(global_annual, overwrite = T)
xgb_stack
library(APMtools)
xgb_stack
library(xgboost)
?xgboost
100000/60
100000/60/24
install_github("mengluchu/APMtools")
library(APMtools)
library(devtools)
install_github("mengluchu/APMtools")
library(APMtools)
xgboost_imp
xgboost_imp
library(APMtools)
xgboost_imp
#' Lasso model for LUR, crossvalidation, default fold (10)
#' @param  variabledf the dataframe containing predictors and dependent variable
#' @param y_varname  name of the dependent variable.
#' @param training the index for the rows used for training.
#' @param test the index for the rows used for testing.
#' @param grepstring the variable/column names of predictors in Lasso, grepl stlye, e.g. 'ROAD|pop|temp|wind|Rsp|OMI|eleva|coast'
#' @return  error matrix, plot selected (min MSE ) coefficients
#' @export
Lasso = function(variabledf, vis1 = T, alpha = 1, printlambda =F, y_varname, training, test, grepstring ) {
prenres = paste(y_varname, "|", grepstring, sep = "")
pre_mat_all = subset_grep(variabledf, prenres)
pre_mat = pre_mat_all%>%dplyr::select(-y_varname)
pre_mat_tr = pre_mat[training, ]
pre_mat_test = pre_mat[test, ]
y_tr_value = variabledf[training, y_varname]
y_test_value = variabledf[test, y_varname]
cvfit <- glmnet::cv.glmnet(as.matrix(pre_mat_tr), y_tr_value, type.measure = "mse", standardize = TRUE, alpha = alpha, lower.limit = 0)
if (printlambda){
print(paste("min:" cvfit$lambda.min))
print(paste("1se:"cvfit$lambda.1se))}
if (vis1) {
plot(cvfit)
Lassoselected(cvfit)
}
elastic_pred = predict(cvfit, newx = as.matrix(pre_mat_test))
error_matrix(y_test_value, elastic_pred)
}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('global_crossvali',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "png", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "xgboost",  "glmnet", "ranger", "randomForest","tidyr" ,"tibble","stargazer")
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
resolution =100
y_var = "mean_value"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|radi"
varstring = paste(prestring,y_var,sep="|")
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('global_crossvali',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "png", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "xgboost",  "glmnet", "ranger", "randomForest","tidyr" ,"tibble","stargazer")
ipak(packages)
install_github("mengluchu/APMtools")
library(APMtools)
resolution =100
y_var = "mean_value"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|radi"
varstring = paste(prestring,y_var,sep="|")
mergedall = read.csv("~/Documents/GitHub/uncertainty/data_vis_exp/DENL17_uc.csv")
mergedall$AirQualityStationArea%>%table
mergedall$AirQualityStationType%>%table
mergedall%>%filter(AirQualityStationType=="traffic")%>%dplyr::select(wkd_day_value)%>%summary
mergedall%>%filter(AirQualityStationType=="traffic")%>%dplyr::select(wkd_night_value)%>%summary
mergedall%>%filter(AirQualityStationType=="background")%>%dplyr::select(wkd_day_value)%>%summary
mergedall%>%filter(AirQualityStationType=="background")%>%dplyr::select(wkd_night_value)%>%summary
merged = mergedall%>%dplyr::select(matches(varstring))%>%  na.omit()
names(merged)
if (resolution ==100)
{
merged = merged%>%dplyr::select(-c(industry_25,industry_50,road_class_1_25,road_class_1_50,road_class_2_25,road_class_2_50,   road_class_3_25,road_class_3_50))
}
names(merged)
merged$population_1000%>%summary()
traffic_lowpop = merged%>%filter(road_class_2_100 > 0 | road_class_1_100 > 0 & population_1000 > mean(population_1000))
head(traffic_lowpop)
merged$population_1000%>%summary()
merged$population_1000%>%quantile(0.75)
traffic_highpop = merged%>%filter(road_class_2_100 > 0 | road_class_1_100 > 0 & population_1000 > quntile(population_1000, 0.75))
traffic_highpop = merged%>%filter(road_class_2_100 > 0 | road_class_1_100 > 0 & population_1000 > quantile(population_1000, 0.75))
head(traffic_lowpop)
head(traffic_highop)
head(traffic_highpop)
head(traffic_highpop$population_1000)
traffic_highpop$population_1000
merged$population_1000%>%quantile(0.75)
traffic_highpop$population_1000
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0) & population_1000 > quantile(population_1000, 0.75))
traffic_highpop$population_1000
merged$road_class_1_100%>%quantile(0.75)
merged$road_class_2_100%>%quantile(0.75)
merged$road_class_2_100%>%quantile(0.9)
merged$road_class_2_100%>%quantile(0.8)
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0) & population_1000 > quantile(population_1000, 0.75))
traffic_highpop$population_1000
merged$road_class_3_100%>%quantile(0.8)
merged$road_class_3_100%>%quantile(0.7)
merged$road_class_3_100%>%quantile(0.5)
merged$road_class_3_100%>%quantile(0.75)
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
traffic_highpop$population_1000
traffic_lowpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.25))
traffic_lowpop$population_1000
traffic_lowpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
traffic_lowpop$population_1000
traffic_lowpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.25))
traffic_lowpop$population_1000
traffic_lowpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
traffic_lowpop$population_1000
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
traffic_highpop$population_1000
traffic_lmpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
traffic_lowpop$population_1000
summary( traffic_lowpop$population_1000)
summary( traffic_highpop$population_1000)
orderedall = rbind(traffic, background, indu)
summary( traffic_lowpop$population_1000)
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100>quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75))
summary( traffic_highpop$population_1000)
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.5))
summary( traffic_highpop$population_1000)
traffic_highpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
summary( traffic_highpop$population_1000)
traffic_lmpop = merged%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
summary( traffic_lowpop$population_1000)
fartr_highpop = merged%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75))
fartr_lmpop = merged%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 < quantile(population_1000, 0.5))
traffic_highpop
traffic_highpop$mean_value
traffic_highpop$mean_value%>%summary
other =
gp=cbind(traffic_highpop, traffic_lmpop, fartr_highpop, fartr_lmpop)
gp=cbind(traffic_highpop, traffic_lmpop, fartr_highpop, fartr_lmpop)
gp=cbind(traffic_highpop, traffic_lmpop, fartr_highpop, fartr_lmpop)
gp=rbind(traffic_highpop, traffic_lmpop, fartr_highpop, fartr_lmpop)
other = setdiff(merged, gp)
nrow(gp)
nrow(other)
nrow(gp)
nrow(other)
sp3_cv =  function(n, df_type= c("traffic", "background", "industrial") , df_all, df_model, y_var) {
set.seed(n)
totest = df_all%>%filter(AirQualityStationType==df_type) %>%dplyr::select(colnames(df_model))
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
sp_tra = lapply(1:20, df =orderedall, df_type=traffic, y_var = y_var, sp3_cv)%>%data.frame()
sp3_cv =  function(n, df_type= c("traffic", "background", "industrial") , df_all, df_model, y_var) {
set.seed(n)
totest = df_all%>%filter(AirQualityStationType==df_type) %>%dplyr::select(colnames(df_model))
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
sp_tra = lapply(1:20, df ="traffic", df_type=traffic, y_var = y_var, sp3_cv)%>%data.frame()
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
sp3_cv =  function(n, df_type= c("traffic", "background", "industrial") , df_all, df_model, y_var) {
set.seed(n)
totest = df_all%>%filter(AirQualityStationType==df_type) %>%dplyr::select(colnames(df_model))
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
df_all = mergedall
df_type ="traffic"
df_model =merged
totest = df_all%>%filter(AirQualityStationType==df_type) %>%dplyr::select(colnames(df_model))
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
training
test
sp3_cv =  function(n, df_type= c("traffic", "background", "industrial") , df_all, df_model, y_var) {
set.seed(n)
totest = df_all%>%filter(AirQualityStationType==df_type) %>%dplyr::select(colnames(df_model))
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df_model, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
sp_bg= lapply(1:20, df_type ="background",df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
F1 = function(m, pre, f=quote(summary), nvaria) {apply(pre[, seq(m, ncol(pre), by =nvaria)], 1, f)}
nv = 3# number of algorithms.
cv_traffic= data.frame(sapply(1:nv, F1, sp_tra, mean,nv))
names(cv_traffic) = paste0(c("LA", "RF", "XGB"), "_tra")
cv_bg = data.frame(sapply(1:nv, F1, sp_bg, mean,nv))
names(cv_bg) =  paste0(c("LA", "RF", "XGB"),"_bg")
cbind(cv_traffic, cv_bg)
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
summary( traffic_highpop$population_1000),
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))  ,
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))  ,
#fartr_highpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75)),
#fartr_lmpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 < quantile(population_1000, 0.5))
)
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df_model, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
tr_hp = lapply(1:20, df_type ="tr_hp", df_all = mergedall, df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
tr_lmp= lapply(1:20, df_type ="tr_lmp", df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(df_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))  ,
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))  ,
#fartr_highpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75)),
#fartr_lmpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 < quantile(population_1000, 0.5))
)
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df_model, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
tr_hp = lapply(1:20, df_type ="tr_hp",  df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
tr_lmp= lapply(1:20, df_type ="tr_lmp", df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
#' predict tiles using LA, RF, SGB
#' @param df the dataframe for building the model
#' @param rasstack rasterstack, predictors
#' @param yname the y variable name
#' @param xgbname output filename for xgb
#' @param rfname output filename for rf
#' @param lanme output filename for LA
#' @param ntree RF ntree, default 1000
#' @examples
#' \donttest{
#' xgbname = "/data/lu01/NWA/xgb6-Jul_oaq.tif"
#' rfname = "/data/lu01/NWA/RF6-Juloaq.tif"
#' laname= "/data/lu01/NWA/LA6-Juloaq.tif"
#' lus = raster("/data/lu01/NWA/predictor/NLstack.grd")
#' lf_lo = list.files("/data/lu01/NWA/Bakfietsdata", pattern = "^.*morning.*.csv$", full.names = T)
#' bakfile1 = read.csv(lf_lo[1])
#' proj = "+proj=longlat +datum=WGS84"
#' df = retrieve_predictor(lus, bakfile1, c("Lon", "Lat"), proj)
#' predicLA_RF_XGBtiles(df, lus, "NO2", xgbname=xgbname, rfname = rfname, laname = laname )}
#' @export
predicLA_RF_XGBtiles <-function(df, rasstack, yname,  xgbname, rfname, laname, ntree, mtry,  nrounds = 3000, eta = 0.007, gamma =5,max_depth = 6, xgb_alpha = 0, xgb_lambda = 2, subsample=0.7,...){
predfun <- function(model, data) {
v <- predict(model, as.matrix(data ))
}
#indep_dep = subset_grep(df, paste0(yname,"|",varstring) # RESPONSE+PREDICTOR matrix
#varstring=NULL; pre_mat3 = ifelse(is.null(varstring), df, subset_grep(df, varstring)) # prediction matrix
# reorder the dataframe!
re = names(rasstack)
pre_mat3 = df%>% dplyr::select (re)
# make sure the nams match!
stopifnot(all.equal(names(rasstack), names(pre_mat3)))
pre_mat3 = na.omit(pre_mat3)
# .$y
yvar = df%>% dplyr::select(yname)%>%unlist()
#yvar = df%>% .$yname
indep_dep = data.frame(yvar = yvar, pre_mat3)
names(indep_dep)[1]="yvar"
formu = as.formula(paste("yvar", "~.", sep = ""))
##RF
bst = randomForest(formu, data = indep_dep, ntree = ntree, mtry = mtry )
#save(bst, file = "rf_bst.rdata")
sdayR = predict(rasstack, bst)
writeRaster(sdayR,rfname , overwrite = TRUE )
# LA
L_day <- glmnet::cv.glmnet(as.matrix(pre_mat3), yvar, type.measure = "mse", standardize = TRUE, alpha = 1,  lower.limit = 0)
#save(L_day, file = "L_day.rdata")
sdayL = predict(rasstack, L_day, fun = predfun)
writeRaster(sdayL, laname, overwrite = TRUE )
#xgb
#pre_mat3$NO2  = inde_var$NO2
xgb_stack(sr=rasstack, df_var = indep_dep, y_var = "yvar", xgbname = xgbname,
nrounds = nrounds, eta =eta, gamma =gamma,max_depth = max_depth, xgb_alpha = xgb_alpha, xgb_lambda = xgb_lambda, subsample=subsample)
}
do.document()
library(devtools)
document()
document()
document()
read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
glo4var= read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
library(devtools)
use_data(glo4var, overwrite = T)

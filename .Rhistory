cbind(LA,RF,XGB)
}
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
sp_tra = lapply(1:20, df_type ="traffic", df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
sp_bg= lapply(1:20, df_type ="background",df_all = mergedall, df_model =merged, y_var = y_var, sp3_cv)%>%data.frame()
F1 = function(m, pre, f=quote(summary), nvaria) {apply(pre[, seq(m, ncol(pre), by =nvaria)], 1, f)}
nv = 3# number of algorithms.
cv_traffic= data.frame(sapply(1:nv, F1, sp_tra, mean,nv))
names(cv_traffic) = paste0(c("LA", "RF", "XGB"), "_tra")
cv_bg = data.frame(sapply(1:nv, F1, sp_bg, mean,nv))
names(cv_bg) =  paste0(c("LA", "RF", "XGB"),"_bg")
cbind(cv_traffic, cv_bg)
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
summary( traffic_highpop$population_1000),
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(dy_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))  ,
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))  ,
#fartr_highpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75)),
#fartr_lmpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 < quantile(population_1000, 0.5))
)
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df_model, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
tr_hp = lapply(1:20, df_type ="tr_hp", df_all = mergedall, df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
tr_lmp= lapply(1:20, df_type ="tr_lmp", df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
sp2_cv =  function(n, df_type= c("tr_hp", "tr_mlp", "f_hp","f_mlp") , df_model, y_var) {
set.seed(n)
methodID = switch(df_type,  "tr_hp"=1,"tr_mlp" =2,"f_hp"=3, "f_mlp"=4 )
totest = switch(methodID,
#traffic_highpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0|road_class_3_100>quantile(road_class_3_100, .75)) & population_1000 > quantile(population_1000, 0.75))  ,
#traffic_lmpop
df_model%>%filter((road_class_2_100 > 0 | road_class_1_100 > 0 |road_class_3_100 > quantile(road_class_3_100, .75)) & population_1000 < quantile(population_1000, 0.5))  ,
#fartr_highpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 > quantile(population_1000, 0.75)),
#fartr_lmpop
df_model%>%filter((road_class_2_100 == 0 & road_class_1_100 == 0 & road_class_3_100 < quantile(road_class_3_100, .5)) & population_1000 < quantile(population_1000, 0.5))
)
others = setdiff(df_model, totest)
orderedall=rbind(totest, others)
test_size = floor(0.2*nrow(df_model)) # 30  is about 20% of traffic, use a consistent size about 7% of data
test = sample(nrow(df_model), size = test_size) # sample 20% from e.g. traffic and then use others as training
training = setdiff(seq_len(nrow(df_model)), test)
XGB = xgboost_LUR(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring,  max_depth =6, gamma=5, eta =0.007, nrounds = 3000, xgb_lambda = 2, xgb_alpha = 0, subsample = 0.7)
RF = rf_LUR(df_model, numtrees =  1000, mtry = 34, vis1 = F,y_varname= y_var, training=training, test=test, grepstring =varstring)
LA = Lasso(df_model, y_varname= y_var, training=training, test=test, grepstring =varstring, vis1 = F)
cbind(LA,RF,XGB)
}
tr_hp = lapply(1:20, df_type ="tr_hp",  df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
tr_lmp= lapply(1:20, df_type ="tr_lmp", df_model =merged, y_var = y_var, sp2_cv)%>%data.frame()
#' predict tiles using LA, RF, SGB
#' @param df the dataframe for building the model
#' @param rasstack rasterstack, predictors
#' @param yname the y variable name
#' @param xgbname output filename for xgb
#' @param rfname output filename for rf
#' @param lanme output filename for LA
#' @param ntree RF ntree, default 1000
#' @examples
#' \donttest{
#' xgbname = "/data/lu01/NWA/xgb6-Jul_oaq.tif"
#' rfname = "/data/lu01/NWA/RF6-Juloaq.tif"
#' laname= "/data/lu01/NWA/LA6-Juloaq.tif"
#' lus = raster("/data/lu01/NWA/predictor/NLstack.grd")
#' lf_lo = list.files("/data/lu01/NWA/Bakfietsdata", pattern = "^.*morning.*.csv$", full.names = T)
#' bakfile1 = read.csv(lf_lo[1])
#' proj = "+proj=longlat +datum=WGS84"
#' df = retrieve_predictor(lus, bakfile1, c("Lon", "Lat"), proj)
#' predicLA_RF_XGBtiles(df, lus, "NO2", xgbname=xgbname, rfname = rfname, laname = laname )}
#' @export
predicLA_RF_XGBtiles <-function(df, rasstack, yname,  xgbname, rfname, laname, ntree, mtry,  nrounds = 3000, eta = 0.007, gamma =5,max_depth = 6, xgb_alpha = 0, xgb_lambda = 2, subsample=0.7,...){
predfun <- function(model, data) {
v <- predict(model, as.matrix(data ))
}
#indep_dep = subset_grep(df, paste0(yname,"|",varstring) # RESPONSE+PREDICTOR matrix
#varstring=NULL; pre_mat3 = ifelse(is.null(varstring), df, subset_grep(df, varstring)) # prediction matrix
# reorder the dataframe!
re = names(rasstack)
pre_mat3 = df%>% dplyr::select (re)
# make sure the nams match!
stopifnot(all.equal(names(rasstack), names(pre_mat3)))
pre_mat3 = na.omit(pre_mat3)
# .$y
yvar = df%>% dplyr::select(yname)%>%unlist()
#yvar = df%>% .$yname
indep_dep = data.frame(yvar = yvar, pre_mat3)
names(indep_dep)[1]="yvar"
formu = as.formula(paste("yvar", "~.", sep = ""))
##RF
bst = randomForest(formu, data = indep_dep, ntree = ntree, mtry = mtry )
#save(bst, file = "rf_bst.rdata")
sdayR = predict(rasstack, bst)
writeRaster(sdayR,rfname , overwrite = TRUE )
# LA
L_day <- glmnet::cv.glmnet(as.matrix(pre_mat3), yvar, type.measure = "mse", standardize = TRUE, alpha = 1,  lower.limit = 0)
#save(L_day, file = "L_day.rdata")
sdayL = predict(rasstack, L_day, fun = predfun)
writeRaster(sdayL, laname, overwrite = TRUE )
#xgb
#pre_mat3$NO2  = inde_var$NO2
xgb_stack(sr=rasstack, df_var = indep_dep, y_var = "yvar", xgbname = xgbname,
nrounds = nrounds, eta =eta, gamma =gamma,max_depth = max_depth, xgb_alpha = xgb_alpha, xgb_lambda = xgb_lambda, subsample=subsample)
}
do.document()
library(devtools)
document()
document()
document()
read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
glo4var= read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
library(devtools)
use_data(glo4var, overwrite = T)
library(raster)
raster("~/Downloads/w_01-0000000000-0000000000.tif")
plot(raster("~/Downloads/w_01-0000000000-0000000000.tif"))
raster("~/Downloads/w_annual-0000000000-0000000000-024.tif")
library(raster)
raster("~/Downloads/w_annual-0000000000-0000000000-024.tif")
raster("~/Downloads/w_annual-0000000000-0000023296-012.tif.tif")
raster("~/Downloads/w_annual-0000000000-0000023296-012.tif")
library(rasterVis)
r = raster("~/Downloads/w_annual-0000000000-0000023296-012.tif")
levelplot(r,
col.regions = viridis,
xlab = NULL, ylab = NULL,
scales = list(draw = FALSE),
names.attr = paste("Band", seq_len(nlayers(r))),
maxpixels = 1e6)
levelplot(r,
col.regions = viridis,
xlab = NULL, ylab = NULL,
scales = list(draw = FALSE),
names.attr = paste("Band", seq_len(nlayers(r))),
maxpixels = 1e4)
r1 = raster("/Volumes/Meng_Mac/globalS5p/w_annual-0000000000-0000000000-024.tif")
r2 = raster("/Volumes/Meng_Mac/globalS5p/w_annual-0000000000-0000023296-012.tif")
r3 = mosaic(r1, r2)
r3 = mosaic(r1, r2, fun = mean)
writeRaster(r3, "/Volumes/Meng_Mac/globalS5p/S5p2019.tif")
raster( "/Volumes/Meng_Mac/globalS5p/S5p2019.tif")
r1
r2
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('hourly_8',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "pdf", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"  , "gridExtra"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
glo4var= read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
library(devtools)
use_data(glo4var, overwrite = T)
use_data(glo4var, overwrite = T)
glo4var
names(glo4var)
write.csv(glo4var_2021, "~/Documents/GitHub/Global mapping/predictorF2020_data/glo4var_2021.csv")
write.csv(glo4var_2021, "~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
names(glo4var_2021)
mergefileslatlon = function(lf, no2df, na_val = -9999.990){
allf = lapply(lf, read.csv)
allf = allf %>% reduce(left_join, by = "id")
a=merge(no2df, allf, by.x = c("Longitude", "Latitude") , by.y = c("long.x", "lat.x"))
#select and replace na_val to na
y_var = "value"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|Latitude$|Longitude$|radia|nightlight"
varstring = paste(prestring,y_var,sep="|")
glo4vairbales = a%>%dplyr::select(matches(varstring))%>% dplyr::na_if(na_val)
#glo4vairbales%>%replace_with_na_all(condition = ~.x == na_val)%>%summary
}
# 4 variables + mean_value, using predictors of 2021
lf = list.files( "/Volumes/Meng_Mac/archived_globaldata /station_values/",full.names = T)
no2df = read.csv("/Volumes/Meng_Mac/archived_globaldata /glo4variables.csv")%>%dplyr::select(matches("value|Longitude|Latitude"))
no2df = no2df %>% dplyr::na_if(-1)%>%na.omit()
# row 6011, col 73 , 7 + 66(predictors, 8 25 -50 m, 58 (because no OMI and Rsp) from 100m,  only tropomi, radi, elev, night*4, OSM: 6*4, climate*24)
glo4var_2021 = mergefileslatlon (lf, no2df, na_val = -9999.990)
glo4var_2021 = glo4var_2021%>%rename(TROP_2018 = 'trop_mean_filt.x',trop_mean_filt_2019 = 'trop_mean_filt.y')
names(glo4var_2021)
write.csv(glo4var_2021, "~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
cor(glo4var_2021$trop_mean_filt_2019,glo4var_2021$TROP_2018)
library(tidyverse)
library(purrr)
library(data.table)
library(naniar)
mergefileslatlon = function(lf, no2df, na_val = -9999.990){
allf = lapply(lf, read.csv)
allf = allf %>% reduce(left_join, by = "id")
a=merge(no2df, allf, by.x = c("Longitude", "Latitude") , by.y = c("long.x", "lat.x"))
#select and replace na_val to na
y_var = "value"
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|Latitude$|Longitude$|radia|nightlight"
varstring = paste(prestring,y_var,sep="|")
glo4vairbales = a%>%dplyr::select(matches(varstring))%>% dplyr::na_if(na_val)
#glo4vairbales%>%replace_with_na_all(condition = ~.x == na_val)%>%summary
}
# 4 variables + mean_value, using predictors of 2021
lf = list.files( "/Volumes/Meng_Mac/archived_globaldata /station_values/",full.names = T)
no2df = read.csv("/Volumes/Meng_Mac/archived_globaldata /glo4variables.csv")%>%dplyr::select(matches("value|Longitude|Latitude"))
no2df = no2df %>% dplyr::na_if(-1)%>%na.omit()
# row 6011, col 73 , 7 + 66(predictors, 8 25 -50 m, 58 (because no OMI and Rsp) from 100m,  only tropomi, radi, elev, night*4, OSM: 6*4, climate*24)
glo4var_2021 = mergefileslatlon (lf, no2df, na_val = -9999.990)
glo4var_2021 = glo4var_2021%>%rename(TROP_2018 = 'trop_mean_filt.x',trop_mean_filt_2019 = 'trop_mean_filt.y')
names(glo4var_2021)
write.csv(glo4var_2021, "~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
cor(glo4var_2021$trop_mean_filt_2019,glo4var_2021$TROP_2018)
glo4var= read.csv("~/Documents/GitHub/Global mapping/predictorF2021_data/glo4var_2021.csv")
library(devtools)
use_data(glo4var, overwrite = T)
names(glo4var)
xgb_stack = function(sr, df_var, y_var, xgbname= "xgb.tif",max_depth,
eta, gamma, nrounds, subsample,
verbose = 0, xgb_lambda, xgb_alpha, grepstring){
dfpredict = subset_grep(df_var, grepstring)
sr=  subset(sr, names(dfpredict))
re = names(sr)
pre_mat3 = df_var %>% dplyr::select(re)
stopifnot(all.equal(names(sr), names(pre_mat3)))
pre_mat3=df_var
yvar = df_var%>% dplyr::select(y_var) %>% unlist()
#indep_dep = data.frame(yvar = yvar, pre_mat3)
#df1 = data.table(indep_dep, keep.rownames = F)
#formu = as.formula(paste("yvar", "~.-1", sep = ""))
#dfmatrix = sparse.model.matrix(formu, data = df1) #seems have to drop na this way
dfmatrix =  as.matrix(pre_mat3)
bst <- xgboost(data = dfmatrix, label = yvar, max_depth = max_depth, subsample = subsample,
eta = eta,   gamma = gamma, nrounds = nrounds,
verbose = verbose, lambda = xgb_lambda, alpha =xgb_alpha)
predfun <- function(model, data) {
v <- predict(model, as.matrix(data))
}
b= predict(sr, bst, fun = predfun)
writeRaster(b, filename =  xgbname, overwrite=TRUE)}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path=paste0('hourly_8',"/"),
echo=F, warning=FALSE, message=FALSE, dev = "pdf", include = T)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
predicLA_RF_XGBtiles
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr","data.table" , "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
predicLA_RF_XGBtiles
?subset
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr",  "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
subset
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr",  "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr",  "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE , repos='http://cran.muenster.r-project.org')
sapply(pkg, require, character.only = TRUE)
}
packages <- c( "devtools", "dplyr",  "ggplot2" , "RColorBrewer", "raster", "rasterVis", "rgdal","Matrix","xgboost",  "glmnet", "ranger", "randomForest"
,"tidyverse" )
ipak(packages)
install_github("mengluchu/APMtools")
#update.packages("sf")
library(raster)
library(APMtools)
Lassoselected
lassoselected
APMtools::lassoselected(cvfit)
# get the entire distribution
Ls= lassoselected(cvfit)
# get the entire distribution
Ls= lassoselected(cvfit)
#' Plot coefficients of Lasso selected variables
#' @param cvfit the result of cvfit
#' @export
lassoselected = function(cvfit) {
coefall <- coef(cvfit)[-1]  # lambda.1se
coefselected <- which(coefall != 0)
allvarnames = dimnames(coef(cvfit))[[1]][-1]
selectedvarnames = allvarnames[coefselected]
selectedcoef = coefall[coefselected]
ENcoef = selectedcoef
namesENcoef <- selectedvarnames
ENcoefdf <- data.frame(x = namesENcoef, y = ENcoef, stringsAsFactors = F)
ag = ggplot(ENcoefdf, aes(x = x, y = y)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + labs(title = "coefficient elastic net 0.5", y = "coefficient")
print(ag)
return(namesENcoef)
}
# get the entire distribution
Ls= lassoselected(cvfit)
prediction_with_pp_La = function(rfmodel, trainingXY, trainingY, testingX)
{
allp = predict(rfmodel,trainingXY , predict.all = T)%>%predictions #get all the tree predictions, instead of the mean
cvfit <- glmnet::cv.glmnet(allp,trainingY ,
type.measure = "mse", standardize = TRUE, alpha = 1,
lower.limit = 0)
# aggregate using a regularization, here lasso, you can also do elastic net, training alpha or specify alpha between 0 and 1
rpre= predict(rfmodel,testingX, predict.all=T)%>%predictions # get all the tree predictions
# prediction
pred = predict(cvfit, newx = rpre) # use the regularization (here lasso) model to predict
# get the entire distribution
Ls= lassoselected(cvfit)
Ls_num= as.vector(sapply(Ls, function(x) as.numeric(substr(x, start =2, stop = nchar(x)))))
# aggregating trees using lasso, compare with original random forest, obtained better results
reduced_rf = rpre[,Ls_num] # 62 trees
return(list(pred, reduced_rf))
}
library(APMtools)
library(APMtools)
variabledf = df
prenres = paste(y_varname, "|", grepstring, sep = "")
y_varname = "value_mean"
prenres = paste(y_varname, "|", grepstring, sep = "")
grepstring = varstring
prestring =  "road|nightlight|population|temp|wind|trop|indu|elev|radi"
varstring = paste(prestring,y_var,sep="|")
y_var = "mean_value"
prenres = paste(y_varname, "|", grepstring, sep = "")
grepstring =varstring
grepstring =prestring
prenres = paste(y_varname, "|", grepstring, sep = "")
pre_mat = subset_grep(variabledf[training, ], prenres)
training  = 1:100
test = 120=140
test = 120:140
pre_mat = subset_grep(variabledf[training, ], prenres)
y_test = variabledf[test, y_varname]
x_test = variabledf[test, ]
pre_mat = subset_grep(variabledf[training, ], prenres)
prenres
prenres = paste(y_varname, "|", grepstring, sep = "")
pre_mat = subset_grep(variabledf[training, ], prenres)
training
variabledf
variabledf=merged
pre_mat = subset_grep(variabledf[training, ], prenres)
y_test = variabledf[test, y_varname]
x_test = variabledf[test, ]
formu = as.formula(paste(y_varname, "~.", sep = ""))
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
df = data.frame(imp_val = rf3$variable.importance)
library(ranger)
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
numtrees = 2000
mtry = 33
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees,  importance = "impurity")
df = data.frame(imp_val = rf3$variable.importance)
mtry = NULL
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
rf3
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
mtry = NULL
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
df = data.frame(imp_val = rf3$variable.importance)
rf3
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], as.matrix(variabledf[test,]))
library(dplyr)
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], as.matrix(variabledf[test,]))
rf3
as.matrix(pre_mat)
variabledf[training, y_varname]
as.matrix(variabledf[test,])
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], as.matrix(variabledf[test,]))
variabledf[test,]
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], as.matrix(as.numeric(variabledf[test,])))
as.matrix(as.numeric(variabledf[test,]))
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], as.numeric(as.matrix(variabledf[test,])))
as.numeric(as.matrix(variabledf[test,]))
variabledf[test,]
grepstring
pre_mat = subset_grep(variabledf[training, ], prenres)
str(pre_mat)
variabledf[training, y_varname]
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], x_test))
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], x_test)
library(ggplot2)
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], x_test)
rfcrps = crps_sample(y = y_test, pre[[2]], method = "edf") # rf
library(scoringRules)
rfcrps = crps_sample(y = y_test, pre[[2]], method = "edf") # rf
pre[[2]]
rfcrps
c(error_matrix(y_test, pre[[1]]), crps = rfcrps)
#' Accuracy matrix of aggregating random forest using lasso
#' @param variabledf the dataframe containing predictors and dependent variable
#' @param y_varname  name of the dependent variable.
#' @param training the index for the rows used for training.
#' @param test the index for the rows used for testing.
#' @param grepstring the variable/column names of predictors in Lasso, grepl stlye, e.g. 'ROAD|pop|temp|wind|Rsp|OMI|eleva|coast'
#' @param vis if true, plot variable importance
#' @return plot variable importance and an error matrix
#' @export
rf_Lasso_LUR = function(variabledf, vis = F, numtrees = 1000, mtry = NULL, y_varname = c("day_value", "night_value", "value_mean"), training, test, grepstring, ...) {
prenres = paste(y_varname, "|", grepstring, sep = "")
pre_mat = subset_grep(variabledf[training, ], prenres)
y_test = variabledf[test, y_varname]
x_test = variabledf[test, ]
formu = as.formula(paste(y_varname, "~.", sep = ""))
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
df = data.frame(imp_val = rf3$variable.importance)
if (vis) {
imp_plot = ggplot(df, aes(x = reorder(rownames(df), imp_val), y = imp_val, fill = imp_val)) + geom_bar(stat = "identity", position = "dodge") + coord_flip() + ylab("Variable Importance") + xlab("") + ggtitle(paste("Information Value Summary",                                                                                                                                                                                                                        y_varname, sep = ": ")) + guides(fill = F) + scale_fill_gradient(low = "red", high = "blue")
print(imp_plot)
}
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], x_test)
rfcrps = crps_sample(y = y_test, pre[[2]], method = "edf") # rf
return(c(error_matrix(y_test, pre[[1]]), meancrps = mean(rfcrps), mediancrps = median(rfcrps)))
}
prenres = paste(y_varname, "|", grepstring, sep = "")
pre_mat = subset_grep(variabledf[training, ], prenres)
y_test = variabledf[test, y_varname]
x_test = variabledf[test, ]
formu = as.formula(paste(y_varname, "~.", sep = ""))
rf3 <- ranger(formu, data = pre_mat, num.trees = numtrees, mtry = mtry, importance = "impurity")
df = data.frame(imp_val = rf3$variable.importance)
if (vis) {
imp_plot = ggplot(df, aes(x = reorder(rownames(df), imp_val), y = imp_val, fill = imp_val)) + geom_bar(stat = "identity", position = "dodge") + coord_flip() + ylab("Variable Importance") + xlab("") + ggtitle(paste("Information Value Summary",                                                                                                                                                                                                                        y_varname, sep = ": ")) + guides(fill = F) + scale_fill_gradient(low = "red", high = "blue")
print(imp_plot)
}
pre = prediction_with_pp_La (rf3, as.matrix(pre_mat), variabledf[training, y_varname], x_test)
rfcrps = crps_sample(y = y_test, pre[[2]], method = "edf") # rf
x_test
as.matrix(x_test)
x_test = variabledf[test, ]
prenres = paste(y_varname, "|", grepstring, sep = "")
prenres = paste(y_varname, "|", grepstring, sep = "")
y_test = variabledf[test, y_varname]
x_test = variabledf[test, ]
x_test
grepstring
